# -*- coding: utf-8 -*-
"""foreign_object_segmentation.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1QB6USnS8upEOErlbA3vPhP09TbsJvlTg
"""

#!pip install torch==2.0.1+cu117 torchvision==0.15.2+cu117 torchaudio==2.0.2 --index-url https://download.pytorch.org/whl/cu117

# 1. Önceki sürümleri temizle
#!pip uninstall torch torchvision torchaudio detectron2 -y

# 2. PyTorch + CUDA 12.1 yükle (T4 için optimize)
!pip install torch==2.3.0 torchvision==0.18.0  --index-url https://download.pytorch.org/whl/cu121

# 3. Detectron2'yi derle
!pip install 'git+https://github.com/facebookresearch/detectron2.git@main'

import torch
import detectron2

# PyTorch ve CUDA durumunu kontrol et
print(f"PyTorch sürümü: {torch.__version__}")
print(f"CUDA mevcut: {torch.cuda.is_available()}")

# Detectron2'nin doğru yüklendiğini kontrol et
print(f"Detectron2 sürümü: {detectron2.__version__}")

from google.colab import drive
drive.mount('/content/drive')

#COCO formatındaki veri setini Detectron2'ye tanıtmak için
from detectron2.data.datasets import register_coco_instances

# Eğitim verisini kaydet
register_coco_instances("foreign_object_train", {}, "/content/drive/MyDrive/X-Ray Segmentation.v1i.coco-segmentation/annotations_train/train_annotations_guncel.coco.json", "/content/drive/MyDrive/X-Ray Segmentation.v1i.coco-segmentation/train")


# Test verisini kaydet
register_coco_instances("foreign_object_test", {}, "/content/drive/MyDrive/X-Ray Segmentation.v1i.coco-segmentation/annotations_test/test_annotations_guncel.coco.json", "/content/drive/MyDrive/X-Ray Segmentation.v1i.coco-segmentation/test")

# Validation verisini kaydet
register_coco_instances("foreign_object_val", {}, "/content/drive/MyDrive/X-Ray Segmentation.v1i.coco-segmentation/annotations_valid/valid_annotations_guncel.coco.json", "/content/drive/MyDrive/X-Ray Segmentation.v1i.coco-segmentation/valid")

#yüklemenin başarılı olup olmadığına baktık
from detectron2.utils.visualizer import Visualizer
from detectron2.data import MetadataCatalog, DatasetCatalog
import random
import cv2
import matplotlib.pyplot as plt

# Örnek bir görsel göster (train setinden)
dataset_dicts = DatasetCatalog.get("foreign_object_train") #veri setindeki tüm görsel yolu,maskeler,sınıf bilgilerini getirir
metadata = MetadataCatalog.get("foreign_object_train")#veri setindeki etiket bilgisini getirir

d = random.choice(dataset_dicts)
img = cv2.imread(d["file_name"]) # file_name: rastgele seçilen görselin dosya yolu

#Visualizer rgb ile çalıştığı için görseli rgb'ye çevir
visualizer = Visualizer(img[:, :, ::-1], metadata=metadata, scale=1.0)
out = visualizer.draw_dataset_dict(d) # anatasyonları çizer

# Matplotlib ile göster
plt.figure(figsize=(12, 8))
plt.imshow(out.get_image()[:, :, ::-1]) # rgb'den bgr'ye çevirme
plt.axis("off")
plt.show()

from detectron2.config import get_cfg
from detectron2.engine import DefaultTrainer
from detectron2 import model_zoo # Hazır model konfigürasyonları için
import os

cfg = get_cfg() # Detectron2 yapılandırması için,eğitim ve modelle ilgili tüm ayarlar burada yapılacak

# Mask R-CNN yapılandırmasını kullan (Mask R-CNN + ResNet-50 backbone, FPN. 3x coco modeli)
cfg.merge_from_file(model_zoo.get_config_file("COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml"))

# Eğitim veri seti
cfg.DATASETS.TRAIN = ("foreign_object_train",)
# Test sırasında doğrulama setini kullanılacak
cfg.DATASETS.TEST = ("foreign_object_val",)

cfg.DATALOADER.NUM_WORKERS = 2 # veri yüklemesinde 2 thread kullandık

# Başlangıç model ağırlıkları (COCO ön eğitimli)
cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url("COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml")

cfg.SOLVER.IMS_PER_BATCH = 2 # her adımda 2 görsel işlenecek (batch size)
cfg.SOLVER.BASE_LR = 0.00025  # öğrenme oranı
cfg.SOLVER.MAX_ITER = 1000    # kaç iterasyon eğitileceği, detectron2'de direkt olarak epoch kullanılmaz
cfg.SOLVER.STEPS = []         # LR düşürme adımı yok
cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128  # her bir görselden alınacak örnek sayısı,maskeleri nasıl eğitileceği belirlenir(512'yi de dene)
cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1  # sınıf sayısı (yabancı cisim)

# Eğitim çıktıları buraya kaydedilecek
model_name="model_1"
## 3. Çıktı dizini Google Drive içinde olsun
output_dir = f"/content/drive/MyDrive/detectron2_outputs/{model_name}"

# 4. Klasör yoksa oluştur
os.makedirs(output_dir, exist_ok=True)

# 5. Detectron2 config çıktısını buraya yönlendir
cfg.OUTPUT_DIR = output_dir

from detectron2.engine import DefaultTrainer

trainer = DefaultTrainer(cfg) # modeli oluştur,dataseti yükle,eğitimi başlat ve takip et
trainer.resume_or_load(resume=False) #eğitim sıfırdan başlar
trainer.train()

"""**LOSS GRAFİĞİNİN FONKSİYON HALİ**




"""

import json
import matplotlib.pyplot as plt

def plot_detectron2_loss(log_file_path, show_mask_loss=True):
    total_loss_list = []
    mask_loss_list = []

    try:
        with open(log_file_path, "r") as f:
            for line in f:
                try:
                    data = json.loads(line)
                    if "total_loss" in data:
                        total_loss_list.append(data["total_loss"])
                    if show_mask_loss and "loss_mask" in data:
                        mask_loss_list.append(data["loss_mask"])
                except json.JSONDecodeError:
                    continue

        plt.figure(figsize=(6, 4))
        plt.plot(total_loss_list, label="Total Loss", color="red")
        if show_mask_loss and mask_loss_list:
            plt.plot(mask_loss_list, label="Loss Mask", color="blue")
        plt.xlabel("Iteration")
        plt.ylabel("Loss")
        plt.title("Detectron2 Loss Grafiği")
        plt.legend()
        plt.grid(True)
        plt.show()

plot_detectron2_loss("/content/drive/MyDrive/detectron2_outputs/model_1/metrics.json", show_mask_loss=True)

"""**LOSS BOX REGRESSION FONKSİYON HALİ**"""

import json
import matplotlib.pyplot as plt

def plot_loss_box_reg(log_file_path):
    loss_box_reg_list = []

    try:
        with open(log_file_path, "r") as f:
            for line in f:
                try:
                    data = json.loads(line)
                    if "loss_box_reg" in data:
                        loss_box_reg_list.append(data["loss_box_reg"])
                except json.JSONDecodeError:
                    continue  # JSON hatası varsa satırı atla



        plt.figure(figsize=(6, 4))
        plt.plot(loss_box_reg_list, label="Loss Box Reg", color="red")
        plt.xlabel("Iteration")
        plt.ylabel("Loss Box Reg")
        plt.title("Loss Box Regression Loss Grafiği")
        plt.legend()
        plt.grid(True)
        plt.tight_layout()
        plt.show()

plot_loss_box_reg("/content/drive/MyDrive/detectron2_outputs/model_1/metrics.json")

"""**RASTGELE 10 GÖRSEL FONKSİYONU**




"""

import os
import random
import cv2
import numpy as np
from detectron2.engine import DefaultPredictor
from detectron2.utils.visualizer import Visualizer
from detectron2.data import MetadataCatalog
from google.colab.patches import cv2_imshow

def random_predict_and_visualize(cfg, image_dir, num_samples=10, metadata_name="foreign_object_train", score_thresh=0.5):

    # Model ayarları
    cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, "model_final.pth")
    cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = score_thresh
    cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1  # Tek sınıf

    # Predictor oluştur
    predictor = DefaultPredictor(cfg)

    # Test klasöründeki tüm jpg dosyaları
    image_files = [f for f in os.listdir(image_dir) if f.endswith(".jpg")]

    # Rastgele seçilen görseller
    sampled_images = random.sample(image_files, min(num_samples, len(image_files)))

    for img_file in sampled_images:
        img_path = os.path.join(image_dir, img_file)
        im = cv2.imread(img_path)
        if im is None:
            print(f"Görsel yüklenemedi: {img_file}")
            continue

        # Tahmin yap
        outputs = predictor(im)

        # Görselleştir
        v = Visualizer(im[:, :, ::-1], MetadataCatalog.get(metadata_name), scale=0.8)
        out = v.draw_instance_predictions(outputs["instances"].to("cpu"))
        pred_img = out.get_image()[:, :, ::-1]

        # Görselleri aynı boyuta getir
        height = min(im.shape[0], pred_img.shape[0])
        width = min(im.shape[1], pred_img.shape[1])
        im_resized = cv2.resize(im, (width, height))
        pred_resized = cv2.resize(pred_img, (width, height))

        # Yan yana birleştir
        combined = np.hstack((im_resized, pred_resized))

        print(f"Resim: {img_file}")
        cv2_imshow(combined)

random_predict_and_visualize(cfg, "/content/drive/MyDrive/X-Ray Segmentation.v1i.coco-segmentation/test", num_samples=10)

"""--------------------------------------**MODEL-2**---------------------------------



"""

from detectron2.config import get_cfg
from detectron2.engine import DefaultTrainer
from detectron2 import model_zoo # Hazır model konfigürasyonları için
import os

cfg = get_cfg() # Detectron2 yapılandırması için,eğitim ve modelle ilgili tüm ayarlar burada yapılacak

# Mask R-CNN yapılandırmasını kullan (Mask R-CNN + ResNet-101 backbone, FPN. 3x coco modeli)
cfg.merge_from_file(model_zoo.get_config_file("COCO-InstanceSegmentation/mask_rcnn_R_101_FPN_3x.yaml"))

# Eğitim veri seti
cfg.DATASETS.TRAIN = ("foreign_object_train",)
# Test sırasında doğrulama setini kullanmak istiyoruz
cfg.DATASETS.TEST = ("foreign_object_val",)

cfg.DATALOADER.NUM_WORKERS = 2 # veri yüklemesinde 2 thread kullandık

# Başlangıç model ağırlıkları (COCO ön eğitimli)
cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url("COCO-InstanceSegmentation/mask_rcnn_R_101_FPN_3x.yaml")

cfg.SOLVER.IMS_PER_BATCH = 2 # her adımda 2 görsel işlenecek (batch size)
cfg.SOLVER.BASE_LR = 0.00025  # öğrenme oranı
cfg.SOLVER.MAX_ITER = 1000    # kaç iterasyon eğitileceği, detectron2'de direkt olarak epoch kullanılmaz
cfg.SOLVER.STEPS = []         # LR düşürme adımı yok
cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128  # her bir görselden alınacak örnek sayısı,maskeleri nasıl eğitileceği belirlenir(512'yi de dene)
cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1  # sınıf sayısı (yabancı cisim)

model_name="model_2"
## 3. Çıktı dizini Google Drive içinde olsun
output_dir = f"/content/drive/MyDrive/detectron2_outputs/{model_name}"

# 4. Klasör yoksa oluştur
os.makedirs(output_dir, exist_ok=True)

# 5. Detectron2 config çıktısını buraya yönlendir
cfg.OUTPUT_DIR = output_dir

from detectron2.engine import DefaultTrainer

trainer = DefaultTrainer(cfg) # modeli oluştur,dataseti yükle,eğitimi başlat ve takip et
trainer.resume_or_load(resume=False) #eğitim sıfırdan başlar
trainer.train()

plot_detectron2_loss("/content/drive/MyDrive/detectron2_outputs/model_2/metrics.json", show_mask_loss=True)

plot_loss_box_reg("/content/drive/MyDrive/detectron2_outputs/model_2/metrics.json")

random_predict_and_visualize(cfg, "/content/drive/MyDrive/X-Ray Segmentation.v1i.coco-segmentation/test", num_samples=10)

"""**MODEL-3**"""

from detectron2.config import get_cfg
from detectron2.engine import DefaultTrainer
from detectron2 import model_zoo # Hazır model konfigürasyonları için
import os

cfg = get_cfg() # Detectron2 yapılandırması için,eğitim ve modelle ilgili tüm ayarlar burada yapılacak

# Mask R-CNN yapılandırmasını kullan (Mask R-CNN + ResNet-101 backbone, FPN. 3x coco modeli)
cfg.merge_from_file(model_zoo.get_config_file("COCO-InstanceSegmentation/mask_rcnn_R_101_FPN_3x.yaml"))

# Eğitim veri seti
cfg.DATASETS.TRAIN = ("foreign_object_train",)
cfg.DATASETS.TEST = ("foreign_object_val",)

cfg.DATALOADER.NUM_WORKERS = 2 # veri yüklemesinde 2 thread kullandık

# Başlangıç model ağırlıkları (COCO ön eğitimli)
cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url("COCO-InstanceSegmentation/mask_rcnn_R_101_FPN_3x.yaml")

cfg.SOLVER.IMS_PER_BATCH = 4
cfg.SOLVER.BASE_LR = 0.00001  # öğrenme oranı
cfg.SOLVER.MAX_ITER = 1000    # kaç iterasyon eğitileceği
cfg.SOLVER.STEPS = (700,900)
cfg.SOLVER.GAMMA=0.1
cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 256  # her bir görselden alınacak örnek sayısı,maskeleri nasıl eğitileceği belirlenir(512'yi de dene)
cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1  # sınıf sayısı (yabancı cisim)

model_name="model_3"
## 3. Çıktı dizini Google Drive içinde olsun
output_dir = f"/content/drive/MyDrive/detectron2_outputs/{model_name}"

# 4. Klasör yoksa oluştur
os.makedirs(output_dir, exist_ok=True)

# 5. Detectron2 config çıktısını buraya yönlendir
cfg.OUTPUT_DIR = output_dir

trainer = DefaultTrainer(cfg)
trainer.resume_or_load(resume=False)
trainer.train()

plot_detectron2_loss("/content/drive/MyDrive/detectron2_outputs/model_3/metrics.json", show_mask_loss=True)

plot_loss_box_reg("/content/drive/MyDrive/detectron2_outputs/model_3/metrics.json")

random_predict_and_visualize(cfg, "/content/drive/MyDrive/X-Ray Segmentation.v1i.coco-segmentation/test", num_samples=10)

"""Farklı model"""

import os
from detectron2.config import get_cfg
from detectron2.engine import DefaultTrainer
from detectron2 import model_zoo
from detectron2.data import transforms as T

# 1. Temel Konfigürasyon
cfg = get_cfg()
cfg.merge_from_file(model_zoo.get_config_file("COCO-InstanceSegmentation/mask_rcnn_R_101_FPN_3x.yaml"))

# 2. Veri Ayarları
cfg.DATASETS.TRAIN = ("foreign_object_train",)
cfg.DATASETS.TEST = ("foreign_object_val",)
cfg.DATALOADER.NUM_WORKERS = 2  # GPU'ya bağlı olarak artırılabilir
cfg.INPUT.MASK_FORMAT = "bitmask"  # X-Ray'ler için optimal format

# 3. Model Ağırlıkları
cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url("COCO-InstanceSegmentation/mask_rcnn_R_101_FPN_3x.yaml")
cfg.MODEL.PIXEL_MEAN = [123.675, 116.280, 103.530]  # COCO mean (RGB)
cfg.MODEL.PIXEL_STD = [58.395, 57.120, 57.375]  # COCO std

# 4. Sadece Maske Odaklı Eğitim (Bounding Box'ları devre dışı bırak)
cfg.MODEL.ROI_BOX_HEAD.NAME = "FastRCNNConvFCHead"
cfg.MODEL.ROI_BOX_HEAD.BBOX_REG_LOSS_TYPE = "smooth_l1"
cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1  # "yabancı_cisim" sınıfı

# 5. Mask Optimizasyonları
cfg.MODEL.ROI_MASK_HEAD.POOLER_RESOLUTION = 14  # Daha detaylı maskeler
cfg.MODEL.ROI_MASK_HEAD.NUM_CONV = 4  # Ek konvolüsyon katmanları
cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 32  # Daha fazla örnek

# 6. Optimizasyon Parametreleri
cfg.SOLVER.IMS_PER_BATCH = 2  # GPU belleğine göre ayarlayın
cfg.SOLVER.BASE_LR = 0.001
cfg.SOLVER.WARMUP_ITERS = 500
cfg.SOLVER.MAX_ITER = 2000
cfg.SOLVER.STEPS = [1500, 1800]  # Learning rate düşürme adımları
cfg.SOLVER.GAMMA = 0.1
cfg.SOLVER.CHECKPOINT_PERIOD = 500  # Her 500 iterasyonda bir kayıt

# 7. Gradient ve Regularization
cfg.SOLVER.CLIP_GRADIENTS.ENABLED = True
cfg.SOLVER.CLIP_GRADIENTS.CLIP_VALUE = 1.0
cfg.MODEL.BACKBONE.FREEZE_AT = 2  # İlk 2 backbone katmanını dondur

# 8. Veri Artırma (Augmentation)
"""
cfg.DATALOADER.AUG_OPS = [
    T.RandomFlip(horizontal=True, vertical=False, prob=0.5),
    T.RandomRotation(angle=[-15, 15]),
    T.RandomBrightness(0.8, 1.2),
    T.RandomContrast(0.8, 1.2),
    T.RandomCrop("relative_range", (0.8, 0.8))  # X-Ray'ler için önemli
]
"""

# 9. Değerlendirme ve Loglama
cfg.TEST.EVAL_PERIOD = 100  # Her 100 iterasyonda bir validasyon
cfg.TEST.DETECTIONS_PER_IMAGE = 50  # X-Ray'lerde genelde az nesne olur

cfg.TENSORBOARD_LOG_DIR = "./tensorboard"  # TensorBoard log dizini
os.makedirs(cfg.TENSORBOARD_LOG_DIR, exist_ok=True)

# 10. Çıktı Dizinleri
cfg.OUTPUT_DIR = "./output"
os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)

# 12. Trainer Başlatma
trainer = DefaultTrainer(cfg)
trainer.resume_or_load(resume=False)

# 13. Eğitimi Başlat
print("Eğitim başlıyor...")
trainer.train()

import json
import matplotlib.pyplot as plt

# Log dosyasının yolu (varsayılan olarak output klasöründedir)
log_file_path = "/content/output/metrics.json"

# Değerleri saklamak için boş listeler
total_loss_list = []
mask_loss_list = []

# JSON satırlarını oku
with open(log_file_path, "r") as f:
    for line in f:
        try:
            data = json.loads(line)
            if "total_loss" in data:
                total_loss_list.append(data["total_loss"])
            if "loss_mask" in data:
                mask_loss_list.append(data["loss_mask"])
        except:
            continue  # JSON hatalarını atla

# Grafik çiz
plt.figure(figsize=(10, 5))
plt.plot(total_loss_list, label="Total Loss", color="red")
plt.plot(mask_loss_list, label="Loss Mask", color="blue")
plt.xlabel("Iteration")
plt.ylabel("Loss")
plt.title("Loss Grafiği")
plt.legend()
plt.grid(True)
plt.show()

import json
import matplotlib.pyplot as plt

# Log dosyasının yolu
log_file_path = "/content/output/metrics.json"

loss_box_reg_list = []

# JSON satırlarını oku
with open(log_file_path, "r") as f:
    for line in f:
        try:
            data = json.loads(line)
            if "loss_box_reg" in data:
                loss_box_reg_list.append(data["loss_box_reg"])
        except:
            continue  # JSON hatalarını atla

# Grafik çizme
plt.figure(figsize=(12, 8))

# loss_box_reg
plt.plot(loss_box_reg_list, label="Loss Box Reg", color="red")
plt.xlabel("Iteration")
plt.ylabel("Loss Box Reg")
plt.title("Loss Box Reg")
plt.legend()
plt.grid(True)

# Grafikleri göster
plt.tight_layout()
plt.show()


# modelin, nesneleri doğru boyutlarda bounding box ile tahmin oranını gösterir

from detectron2.engine import DefaultPredictor
from detectron2.config import get_cfg
from detectron2 import model_zoo
import os
import random
import cv2
import numpy as np
from detectron2.utils.visualizer import Visualizer
from google.colab.patches import cv2_imshow
from detectron2.data import MetadataCatalog

# Config ve predictor ayarları
cfg = get_cfg()
cfg.merge_from_file(model_zoo.get_config_file("COCO-InstanceSegmentation/mask_rcnn_R_101_FPN_3x.yaml"))
cfg.MODEL.WEIGHTS = "/content/output/model_final.pth"  # Model dosyanın yolu
cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5
cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1
predictor = DefaultPredictor(cfg)

# Test klasörü
image_dir = "/content/drive/MyDrive/X-Ray Segmentation.v1i.coco-segmentation/test"
image_files = [f for f in os.listdir(image_dir) if f.endswith(".jpg")]

sampled_images = random.sample(image_files, 10)

for img_file in sampled_images:
    img_path = os.path.join(image_dir, img_file)
    im = cv2.imread(img_path)

    outputs = predictor(im)

    v = Visualizer(im[:, :, ::-1], MetadataCatalog.get("foreign_object_train"), scale=0.8)
    out = v.draw_instance_predictions(outputs["instances"].to("cpu"))
    pred_img = out.get_image()[:, :, ::-1]

    height = min(im.shape[0], pred_img.shape[0])
    width = min(im.shape[1], pred_img.shape[1])
    im_resized = cv2.resize(im, (width, height))
    pred_resized = cv2.resize(pred_img, (width, height))

    combined = np.hstack((im_resized, pred_resized))
    print(f"Resim: {img_file}")
    cv2_imshow(combined)

"""**Model-4**"""

import os
from detectron2.config import get_cfg
from detectron2.engine import DefaultTrainer
from detectron2 import model_zoo
from detectron2.data import transforms as T

cfg = get_cfg()
cfg.merge_from_file(model_zoo.get_config_file("COCO-InstanceSegmentation/mask_rcnn_R_101_FPN_3x.yaml"))

#Veri Ayarları
cfg.DATASETS.TRAIN = ("foreign_object_train",)
cfg.DATASETS.TEST = ("foreign_object_val",)
cfg.DATALOADER.NUM_WORKERS = 2  # GPU'ya bağlı olarak artırılabilir
cfg.INPUT.MASK_FORMAT = "polygon"  # X-Ray'ler için optimal format

#Model Ağırlıkları
cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url("COCO-InstanceSegmentation/mask_rcnn_R_101_FPN_3x.yaml")

#Optimizasyon Parametreleri
cfg.SOLVER.IMS_PER_BATCH = 2  # GPU belleğine göre ayarla
cfg.SOLVER.BASE_LR = 0.001
cfg.SOLVER.WARMUP_ITERS = 200
cfg.SOLVER.MAX_ITER = 2500
cfg.SOLVER.STEPS = [1800, 2200]  # Learning rate düşürme adımları
cfg.SOLVER.GAMMA = 0.1
cfg.SOLVER.CHECKPOINT_PERIOD = 250  # Her 250 iterasyonda bir kayıt

# Gradyan Kırpma
cfg.SOLVER.CLIP_GRADIENTS.ENABLED = True
cfg.SOLVER.CLIP_GRADIENTS.CLIP_VALUE = 1.0

# Backbone Dondurma
cfg.MODEL.BACKBONE.FREEZE_AT = 2  # İlk 2 katman donuk

# Eğitim çıktıları buraya kaydedilecek
model_name="model_4"
output_dir = f"/content/drive/MyDrive/detectron2_outputs/{model_name}"

#Klasör yoksa oluştur
os.makedirs(output_dir, exist_ok=True)

# Detectron2 config çıktısını buraya yönlendir
cfg.OUTPUT_DIR = output_dir

from detectron2.engine import DefaultTrainer

trainer = DefaultTrainer(cfg) # modeli oluştur,dataseti yükle,eğitimi başlat ve takip et
trainer.resume_or_load(resume=False) #eğitim sıfırdan başlar
trainer.train()

plot_detectron2_loss("/content/drive/MyDrive/detectron2_outputs/model_4/metrics.json", show_mask_loss=True)

plot_loss_box_reg("/content/drive/MyDrive/detectron2_outputs/model_4/metrics.json")

random_predict_and_visualize(cfg, "/content/drive/MyDrive/X-Ray Segmentation.v1i.coco-segmentation/test", num_samples=10)

"""**Model-5**"""

import os
from detectron2.config import get_cfg
from detectron2.engine import DefaultTrainer
from detectron2 import model_zoo
from detectron2.data import transforms as T

cfg = get_cfg()
cfg.merge_from_file(model_zoo.get_config_file("COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml"))

#Veri Ayarları
cfg.DATASETS.TRAIN = ("foreign_object_train",)
cfg.DATASETS.TEST = ("foreign_object_val",)
cfg.DATALOADER.NUM_WORKERS = 2
cfg.INPUT.MASK_FORMAT = "polygon"

#Model Ağırlıkları
cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url("COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml")

cfg.INPUT.MIN_SIZE_TRAIN = (512,)
cfg.INPUT.MAX_SIZE_TRAIN = 512
cfg.INPUT.MIN_SIZE_TEST = 512
cfg.INPUT.MAX_SIZE_TEST = 512

#Optimizasyon Parametreleri
cfg.SOLVER.IMS_PER_BATCH = 2  # GPU belleğine göre ayarla
cfg.SOLVER.BASE_LR = 0.0001
cfg.SOLVER.WARMUP_ITERS = 100
cfg.SOLVER.MAX_ITER = 1500
cfg.SOLVER.STEPS = [1800, 1300]  # Learning rate düşürme adımları
cfg.SOLVER.GAMMA = 0.1
cfg.SOLVER.CHECKPOINT_PERIOD = 250  # Her 250 iterasyonda bir kayıt

# Gradyan Kırpma
cfg.SOLVER.CLIP_GRADIENTS.ENABLED = True
cfg.SOLVER.CLIP_GRADIENTS.CLIP_VALUE = 1.0

# Backbone Dondurma
cfg.MODEL.BACKBONE.FREEZE_AT = 4  # İlk 4 katman donuk
cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128
cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1

# Eğitim çıktıları buraya kaydedilecek
model_name="model_5"

output_dir = f"/content/drive/MyDrive/detectron2_outputs/{model_name}"

os.makedirs(output_dir, exist_ok=True)

cfg.OUTPUT_DIR = output_dir

from detectron2.engine import DefaultTrainer

trainer = DefaultTrainer(cfg) # modeli oluştur,dataseti yükle,eğitimi başlat ve takip et
trainer.resume_or_load(resume=False) #eğitim sıfırdan başlar
trainer.train()

plot_detectron2_loss("/content/drive/MyDrive/detectron2_outputs/model_5/metrics.json", show_mask_loss=True)

plot_loss_box_reg("/content/drive/MyDrive/detectron2_outputs/model_5/metrics.json")

random_predict_and_visualize(cfg, "/content/drive/MyDrive/X-Ray Segmentation.v1i.coco-segmentation/test", num_samples=10)

"""**KULLANILACAK MODEL (MODEL-6)**"""

import os
from detectron2.config import get_cfg
from detectron2.engine import DefaultTrainer
from detectron2 import model_zoo
from detectron2.data import transforms as T

cfg = get_cfg()
cfg.merge_from_file(model_zoo.get_config_file("COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml"))

#Veri Ayarları
cfg.DATASETS.TRAIN = ("foreign_object_train",)
cfg.DATASETS.TEST = ("foreign_object_val",)
cfg.DATALOADER.NUM_WORKERS = 2
cfg.INPUT.MASK_FORMAT = "polygon"

#Model Ağırlıkları
cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url("COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml")

cfg.INPUT.MIN_SIZE_TRAIN = (512,)
cfg.INPUT.MAX_SIZE_TRAIN = 512
cfg.INPUT.MIN_SIZE_TEST = 512
cfg.INPUT.MAX_SIZE_TEST = 512

#Optimizasyon Parametreleri
cfg.SOLVER.IMS_PER_BATCH = 4
cfg.SOLVER.BASE_LR = 0.0025
cfg.SOLVER.WARMUP_ITERS = 150
cfg.SOLVER.MAX_ITER = 2000
cfg.SOLVER.STEPS = [1500, 1800]
cfg.SOLVER.GAMMA = 0.1


# Gradyan Kırpma
cfg.SOLVER.CLIP_GRADIENTS.ENABLED = True
cfg.SOLVER.CLIP_GRADIENTS.CLIP_VALUE = 1.0
cfg.MODEL.BACKBONE.FREEZE_AT = 2
cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128
cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1

#Veri artırma
cfg.INPUT.RANDOM_FLIP = "horizontal"
cfg.INPUT.CROP.ENABLED = True
cfg.INPUT.CROP.TYPE = "relative_range"
cfg.INPUT.CROP.SIZE = (0.8, 0.8)  # %20 crop

model_name="model_6"
output_dir = f"/content/drive/MyDrive/detectron2_outputs/{model_name}"

# 4. Klasör yoksa oluştur
os.makedirs(output_dir, exist_ok=True)

# 5. Detectron2 config çıktısını buraya yönlendir
cfg.OUTPUT_DIR = output_dir

from detectron2.engine import DefaultTrainer

trainer = DefaultTrainer(cfg) # modeli oluştur,dataseti yükle,eğitimi başlat ve takip et
trainer.resume_or_load(resume=False) #eğitim sıfırdan başlar
trainer.train()

plot_detectron2_loss("/content/drive/MyDrive/detectron2_outputs/model_6/metrics.json", show_mask_loss=True)

plot_loss_box_reg("/content/drive/MyDrive/detectron2_outputs/model_6/metrics.json")

random_predict_and_visualize(cfg, "/content/drive/MyDrive/X-Ray Segmentation.v1i.coco-segmentation/test", num_samples=10)

"""**BOUNDİNG BOX'LARI KALDIRMA**"""

import os
import random
import cv2
import numpy as np
from detectron2.engine import DefaultPredictor
from detectron2.utils.visualizer import Visualizer, ColorMode
from detectron2.data import MetadataCatalog, DatasetCatalog
from google.colab.patches import cv2_imshow

def rastgele_maskeli_gorselleri_goster_yanyana(cfg, dataset_name="foreign_object_val", adet=10):

    cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, "/content/drive/MyDrive/detectron2_outputs/model_6/model_final.pth")
    cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5
    predictor = DefaultPredictor(cfg)

    veri = DatasetCatalog.get(dataset_name)
    örnekler = random.sample(veri, adet)

    for örnek in örnekler:
        image = cv2.imread(örnek["file_name"])
        outputs = predictor(image)

        instances = outputs["instances"].to("cpu")
        # Bbox'ları kaldır
        instances.pred_boxes.tensor *= 0

        visualizer = Visualizer(
            image[:, :, ::-1],  # BGR->RGB
            MetadataCatalog.get(dataset_name),
            scale=1.0,
            instance_mode=ColorMode.IMAGE_BW
        )

        maskeli_img = visualizer.draw_instance_predictions(instances).get_image()[:, :, ::-1]
        maskeli_img = maskeli_img.copy()
        maskeli_img = maskeli_img.astype("uint8")

        # Skorları yaz
        scores = instances.scores.cpu().numpy()
        boxes = instances.pred_boxes.tensor.cpu().numpy()

        for i, score in enumerate(scores):
            box = boxes[i]
            x, y = int(box[0]), int(box[1])
            text = f"{score:.2f}"
            # Skorları bbox üstüne yaz
            cv2.putText(maskeli_img, text, (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX,
                        0.6, (0, 255, 0), 2, cv2.LINE_AA)

        # Yan yana birleştir
        h = max(image.shape[0], maskeli_img.shape[0])
        w = image.shape[1] + maskeli_img.shape[1]

        combined = np.zeros((h, w, 3), dtype=np.uint8)
        combined[:image.shape[0], :image.shape[1], :] = image
        combined[:maskeli_img.shape[0], image.shape[1]:, :] = maskeli_img

        print(f"Görsel: {os.path.basename(örnek['file_name'])}")
        cv2_imshow(combined)

rastgele_maskeli_gorselleri_goster_yanyana(cfg, dataset_name="foreign_object_val", adet=10)

import os
import random
import cv2
import numpy as np
from detectron2.engine import DefaultPredictor
from detectron2.data import MetadataCatalog, DatasetCatalog
from google.colab.patches import cv2_imshow

def draw_rounded_rectangle(img, top_left, bottom_right, color, radius=5):
    x1, y1 = top_left
    x2, y2 = bottom_right
    r = radius

    # Orta dikdörtgenler
    cv2.rectangle(img, (x1 + r, y1), (x2 - r, y2), color, thickness=cv2.FILLED)
    cv2.rectangle(img, (x1, y1 + r), (x2, y2 - r), color, thickness=cv2.FILLED)

    # 4 adet köşe için çeyrek daireler
    cv2.ellipse(img, (x1 + r, y1 + r), (r, r), 180, 0, 90, color, thickness=cv2.FILLED)
    cv2.ellipse(img, (x2 - r, y1 + r), (r, r), 270, 0, 90, color, thickness=cv2.FILLED)
    cv2.ellipse(img, (x2 - r, y2 - r), (r, r), 0, 0, 90, color, thickness=cv2.FILLED)
    cv2.ellipse(img, (x1 + r, y2 - r), (r, r), 90, 0, 90, color, thickness=cv2.FILLED)


def rastgele_maskeli_gorselleri_goster_yanyana(cfg, dataset_name="foreign_object_val", adet=5):
    cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, "/content/drive/MyDrive/detectron2_outputs/model_6/model_final.pth")
    cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5
    predictor = DefaultPredictor(cfg)

    metadata = MetadataCatalog.get(dataset_name)
    dataset_dicts = DatasetCatalog.get(dataset_name)
    selected_samples = random.sample(dataset_dicts, min(adet, len(dataset_dicts)))


    for d in selected_samples:
        im = cv2.imread(d["file_name"])
        if im is None:
            print("Görsel okunamadı:", d["file_name"])
            continue

        im_masked = im.copy()

        outputs = predictor(im)
        instances = outputs["instances"].to("cpu")
        masks = instances.pred_masks.numpy()
        scores = instances.scores.numpy()

        for i, mask in enumerate(masks):
            color = tuple(random.choices(range(50, 256), k=3))

            # Maskeyi koyu ve transparan yap
            alpha = 0.7
            for c in range(3):
                im_masked[:, :, c] = np.where(mask,
                                              im_masked[:, :, c] * (1 - alpha) + color[c] * alpha,
                                              im_masked[:, :, c])

            # Maskenin etrafına ince kontur çiz (kalınlık=1)
            contours, _ = cv2.findContours(mask.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            cv2.drawContours(im_masked, contours, -1, color, thickness=1)

            # Skor yazısı için koordinat belirle
            yx = np.argwhere(mask)
            if yx.size > 0:
                y_min, x_min = np.min(yx, axis=0)
                x_text = int(x_min)
                y_text = max(int(y_min) - 10, 20)

                # Yazı metni
                text = f"{scores[i]*100:.1f}%"
                # Font ve fontScale (küçük yazı için)
                font = cv2.FONT_HERSHEY_SIMPLEX
                font_scale = 0.3
                thickness = 1

                # Yazı boyutu hesapla
                (text_width, text_height), baseline = cv2.getTextSize(text, font, font_scale, thickness)

                # Yuvarlatılmış köşeli siyah fon için koordinatlar (biraz boşluk bırak)
                padding_x = 2
                padding_y = 1
                rect_x0 = x_text - padding_x
                rect_y0 = y_text - text_height - baseline - padding_y
                rect_x1 = x_text + text_width + padding_x
                rect_y1 = y_text + baseline + padding_y

                draw_rounded_rectangle(im_masked, (rect_x0, rect_y0), (rect_x1, rect_y1), (0, 0, 0), radius=4)

                # Yazıyı beyaz olarak çiz
                cv2.putText(im_masked, text, (x_text, y_text),
                            font, font_scale, (255, 255, 255), thickness, lineType=cv2.LINE_AA)

        height = min(im.shape[0], im_masked.shape[0])
        width = min(im.shape[1], im_masked.shape[1])
        im_resized = cv2.resize(im, (width, height))
        im_masked_resized = cv2.resize(im_masked, (width, height))

        combined = np.hstack((im_resized, im_masked_resized))

        print("Görsel:", os.path.basename(d["file_name"]))
        cv2_imshow(combined)

rastgele_maskeli_gorselleri_goster_yanyana(cfg, dataset_name="foreign_object_val", adet=10)

from detectron2.engine import DefaultPredictor
from detectron2.evaluation import COCOEvaluator, inference_on_dataset
from detectron2.data import build_detection_test_loader

# Ağırlıkları eğitilmiş modelin çıktısından yükle
cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, "/content/drive/MyDrive/detectron2_outputs/model_6/model_final.pth")
cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5  # inference için skor eşiği

# Evaluator tanımla
evaluator = COCOEvaluator("foreign_object_val", cfg, False, output_dir=cfg.OUTPUT_DIR)

# Validation loader hazırla
val_loader = build_detection_test_loader(cfg, "foreign_object_val")

# Değerlendirme yap
metrics = inference_on_dataset(DefaultPredictor(cfg).model, val_loader, evaluator)

# Sonuçları yazdır
print("==== MODEL DEĞERLENDİRME SONUÇLARI ====")
for k, v in metrics["segm"].items():
    print(f"{k}: {v:.2f}")